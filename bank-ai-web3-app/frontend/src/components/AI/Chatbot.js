import React, { useState, useRef, useEffect } from 'react';
import { aiAPI } from '../../services/api';
import './Chatbot.css';

const Chatbot = () => {
  const [messages, setMessages] = useState([
    { 
      role: 'assistant', 
      content: 'Hello! I am your professional banking AI assistant. I support text, voice, and image inputs. How can I help you today?',
      timestamp: new Date().toLocaleTimeString()
    }
  ]);
  const [inputMessage, setInputMessage] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [inputMode, setInputMode] = useState('text'); // 'text', 'voice', 'image'
  const [isRecording, setIsRecording] = useState(false);
  const [selectedImage, setSelectedImage] = useState(null);
  const [imagePreview, setImagePreview] = useState(null);
  const [audioUrl, setAudioUrl] = useState(null);
  
  const chatContainerRef = useRef(null);
  const fileInputRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);

  // automatically roll to the bottom
  useEffect(() => {
    if (chatContainerRef.current) {
      chatContainerRef.current.scrollTop = chatContainerRef.current.scrollHeight;
    }
  }, [messages]);

  // voice recording function
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });   
      //media recorder API
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
        handleVoiceInput(audioBlob);
        stream.getTracks().forEach(track => track.stop());
      };

      mediaRecorder.start();
      setIsRecording(true);
    } catch (error) {
      console.error('Error accessing microphone:', error);
      addErrorMessage('Cannot access microphone. Please check permissions.');
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  };

  // å¤„ç†è¯­éŸ³è¾“å…¥
  const handleVoiceInput = async (audioBlob) => {
    if (!audioBlob) return;

    const formData = new FormData();
    formData.append('audio', audioBlob, 'recording.wav');
    formData.append('message', inputMessage);
    formData.append('user_id', localStorage.getItem('user_id') || 'guest');
    formData.append('generate_audio', 'true'); // è¯·æ±‚è¯­éŸ³å›å¤

    setIsLoading(true);

    try {
      // ä½¿ç”¨api.jsçš„ç»Ÿä¸€é…ç½®
      const response = await aiAPI.chatVoice(
        audioBlob, 
        inputMessage, 
        localStorage.getItem('user_id') || 'guest', 
        true
      );

      const data = response.data;
      
      if (data.success) {
        const userMessage = {
          role: 'user',
          content: data.transcribed_text || '[Voice message]',
          timestamp: new Date().toLocaleTimeString(),
          isVoice: true
        };
        setMessages(prev => [...prev, userMessage]);

  
        const assistantMessage = {
          role: 'assistant',
          content: data.response,
          timestamp: new Date().toLocaleTimeString(),
          sources: data.sources || []
        };
        setMessages(prev => [...prev, assistantMessage]);


        if (data.audio_response) {
          const audioBase64 = data.audio_response;
          const binaryString = atob(audioBase64);
          const bytes = new Uint8Array(binaryString.length);
          for (let i = 0; i < binaryString.length; i++) {
            bytes[i] = binaryString.charCodeAt(i);
          }
          const audioBlob = new Blob([bytes], { type: 'audio/mpeg' });
          const audioUrl = URL.createObjectURL(audioBlob);
          setAudioUrl(audioUrl);
          
          // è‡ªåŠ¨æ’­æ”¾è¯­éŸ³å›å¤
          const audio = new Audio(audioUrl);
          audio.play();
        }
      }
    } catch (error) {
      console.error('Voice chat error:', error);
      addErrorMessage('Failed to process voice message');
    } finally {
      setIsLoading(false);
    }
  };


  const handleImageInput = async () => {
    if (!selectedImage) return;

    const formData = new FormData();
    formData.append('image', selectedImage);
    formData.append('message', inputMessage);
    formData.append('user_id', localStorage.getItem('user_id') || 'guest');

    setIsLoading(true);

    try {
      const response = await aiAPI.chatImage(
        selectedImage, 
        inputMessage, 
        localStorage.getItem('user_id') || 'guest'
      );

      const data = response.data;
      
      if (data.success) {
        // æ·»åŠ ç”¨æˆ·å›¾åƒæ¶ˆæ¯
        const userMessage = {
          role: 'user',
          content: inputMessage || '[Image analysis requested]',
          timestamp: new Date().toLocaleTimeString(),
          image: imagePreview,
          imageAnalysis: data.image_analysis
        };
        setMessages(prev => [...prev, userMessage]);

        // æ·»åŠ AIå›å¤
        const assistantMessage = {
          role: 'assistant',
          content: data.response,
          timestamp: new Date().toLocaleTimeString(),
          sources: data.sources || []
        };
        setMessages(prev => [...prev, assistantMessage]);

        // æ¸…ç©ºå›¾åƒ
        setSelectedImage(null);
        setImagePreview(null);
        setInputMessage('');
      }
    } catch (error) {
      console.error('Image chat error:', error);
      addErrorMessage('Failed to process image');
    } finally {
      setIsLoading(false);
    }
  };

  // send text message
  const sendTextMessage = async (e) => {
    e?.preventDefault();
    if (!inputMessage.trim() || isLoading) return;

    if (inputMode === 'image' && selectedImage) {
      await handleImageInput();
      return;
    }

    // ä½¿ç”¨api.jsçš„aiAPI.chatæ–¹æ³•
    const userMessage = {
      role: 'user',
      content: inputMessage.trim(),
      timestamp: new Date().toLocaleTimeString()
    };
    setMessages(prev => [...prev, userMessage]);
    setInputMessage('');
    setIsLoading(true);

    try {
      // ä½¿ç”¨api.jsçš„ç»Ÿä¸€APIè°ƒç”¨
      const response = await aiAPI.chat({ 
        message: inputMessage.trim(),
        user_id: localStorage.getItem('user_id') || 'guest'
      });

      const data = response.data;
      
      const assistantMessage = {
        role: 'assistant',
        content: data.success ? data.response : 'Sorry, I encountered an error.',
        timestamp: new Date().toLocaleTimeString(),
        sources: data.sources || []
      };
      setMessages(prev => [...prev, assistantMessage]);
    } catch (error) {
      console.error('Text chat error:', error);
      addErrorMessage('Failed to connect to AI service');
    } finally {
      setIsLoading(false);
    }
  };

  // è¾…åŠ©å‡½æ•°ï¼šæ·»åŠ é”™è¯¯æ¶ˆæ¯
  const addErrorMessage = (message) => {
    const errorMessage = {
      role: 'assistant',
      content: message,
      timestamp: new Date().toLocaleTimeString()
    };
    setMessages(prev => [...prev, errorMessage]);
  };

  // å¿«æ·é—®é¢˜ç‚¹å‡»å¤„ç†
  const handleQuickQuestion = (question) => {
    setInputMessage(question);
    setInputMode('text');
  };

  // å›¾åƒé€‰æ‹©å¤„ç†
  const handleImageSelect = (e) => {
    const file = e.target.files[0];
    if (file) {
      if (file.size > 5 * 1024 * 1024) { // 5MBé™åˆ¶
        alert('Image size should be less than 5MB');
        return;
      }

      setSelectedImage(file);
      const reader = new FileReader();
      reader.onloadend = () => {
        setImagePreview(reader.result);
      };
      reader.readAsDataURL(file);
      setInputMode('image');
    }
  };

  // æ¸…é™¤å·²é€‰å›¾åƒ
  const clearImage = () => {
    setSelectedImage(null);
    setImagePreview(null);
    setInputMode('text');
    if (fileInputRef.current) {
      fileInputRef.current.value = '';
    }
  };

  // æ’­æ”¾è¯­éŸ³å›å¤
  const playAudioResponse = () => {
    if (audioUrl) {
      const audio = new Audio(audioUrl);
      audio.play();
    }
  };

  // å‘é€æ¶ˆæ¯çš„ç»Ÿä¸€å…¥å£
  const handleSendMessage = (e) => {
    e?.preventDefault();
    
    switch (inputMode) {
      case 'voice':
        if (isRecording) {
          stopRecording();
        } else {
          startRecording();
        }
        break;
      case 'image':
        if (selectedImage) {
          handleImageInput();
        }
        break;
      default:
        sendTextMessage(e);
    }
  };

  // è·å–å‘é€æŒ‰é’®æ–‡æœ¬
  const getSendButtonText = () => {
    if (isLoading) return 'Processing...';
    if (inputMode === 'voice') {
      return isRecording ? 'ğŸ¤ Stop & Send' : 'ğŸ¤ Start Recording';
    }
    if (inputMode === 'image' && selectedImage) {
      return 'ğŸ“¸ Send Image';
    }
    return 'Send';
  };

  // æ¸²æŸ“æ¶ˆæ¯å†…å®¹
  const renderMessageContent = (msg) => {
    return (
      <div className="message-content">
        <p>{msg.content}</p>
        
        {/* speech message */}
        {msg.isVoice && (
          <div className="voice-indicator">
            <span className="voice-icon">ğŸ¤</span>
            <span className="voice-text">Voice message</span>
          </div>
        )}
        
        {/* image overview */}
        {msg.image && (
          <div className="message-image">
            <img src={msg.image} alt="Uploaded" style={{ maxWidth: '200px', borderRadius: '8px' }} />
            {msg.imageAnalysis && (
              <div className="image-analysis">
                <p className="analysis-title">ğŸ–¼ï¸ Image Analysis:</p>
                <pre style={{ fontSize: '12px', background: '#f5f5f5', padding: '8px' }}>
                  {JSON.stringify(msg.imageAnalysis, null, 2)}
                </pre>
              </div>
            )}
          </div>
        )}
        
        {/* knowledge base sources */}
        {msg.sources && msg.sources.length > 0 && (
          <div className="message-sources">
            <p className="source-title">ğŸ“š Reference Sources:</p>
            <ul>
              {msg.sources.map((source, i) => (
                <li key={i}>
                  <span className="source-relevance">Relevance: {source.relevance}</span>
                  <span className="source-content">{source.content}</span>
                  <span className="source-type">({source.type})</span>
                </li>
              ))}
            </ul>
          </div>
        )}
      </div>
    );
  };

  return (
    <div className="chatbot-wrapper">
      <div className="chatbot-container">
        <div className="chatbot-header">
          <div className="header-content">
            <h2>ğŸ¤– Professional Banking AI Assistant</h2>
            <p>24/7 Intelligent Financial Consultation | Supports Text, Voice & Image</p>
          </div>
          <div className="header-badges">
            <span className="badge badge-voice">ğŸ¤ Voice</span>
            <span className="badge badge-image">ğŸ“¸ Image</span>
            <span className="badge badge-text">ğŸ’¬ Text</span>
          </div>
        </div>

        {/* set input mode */}
        <div className="input-mode-selector">
          <button 
            className={`mode-btn ${inputMode === 'text' ? 'active' : ''}`}
            onClick={() => setInputMode('text')}
            disabled={isLoading}
          >
            <span className="mode-icon">âœï¸</span>
            <span className="mode-text">Text</span>
          </button>
          <button 
            className={`mode-btn ${inputMode === 'voice' ? 'active' : ''}`}
            onClick={() => setInputMode('voice')}
            disabled={isLoading}
          >
            <span className="mode-icon">ğŸ¤</span>
            <span className="mode-text">Voice</span>
          </button>
          <button 
            className={`mode-btn ${inputMode === 'image' ? 'active' : ''}`}
            onClick={() => {
              setInputMode('image');
              fileInputRef.current?.click();
            }}
            disabled={isLoading}
          >
            <span className="mode-icon">ğŸ“¸</span>
            <span className="mode-text">Image</span>
          </button>
        </div>

        {/* chat container */}
        <div className="chat-messages" ref={chatContainerRef}>
          {messages.map((msg, index) => (
            <div key={index} className={`message ${msg.role}`}>
              <div className="message-avatar">
                {msg.role === 'user' ? 'ğŸ‘¤' : 'ğŸ¤–'}
              </div>
              <div className="message-body">
                {renderMessageContent(msg)}
                <div className="message-timestamp">{msg.timestamp}</div>
              </div>
            </div>
          ))}
          
          {isLoading && (
            <div className="message assistant loading">
              <div className="message-avatar">ğŸ¤–</div>
              <div className="message-body">
                <p>
                  {inputMode === 'voice' ? 'Processing voice...' : 
                   inputMode === 'image' ? 'Analyzing image...' : 'Thinking...'}
                </p>
                <div className="loading-dots">
                  <span>.</span><span>.</span><span>.</span>
                </div>
              </div>
            </div>
          )}
        </div>

        {/* å›¾åƒé¢„è§ˆåŒºåŸŸ */}
        {imagePreview && (
          <div className="image-preview">
            <img src={imagePreview} alt="Preview" style={{ maxWidth: '150px' }} />
            <button onClick={clearImage} className="clear-image-btn">
              <span>âœ•</span>
              <span>Remove</span>
            </button>
          </div>
        )}

        {/* å¿«æ·é—®é¢˜åŒºåŸŸ */}
        <div className="quick-questions">
          <p className="quick-title">ğŸ’¡ Common Questions:</p>
          <div className="quick-buttons">
            <button 
              onClick={() => handleQuickQuestion('What is the current deposit interest rate?')}
              disabled={isLoading}
            >
              ğŸ’° Deposit Interest Rate
            </button>
            <button 
              onClick={() => handleQuickQuestion('How to apply for a credit card?')}
              disabled={isLoading}
            >
              ğŸ’³ Credit Card Application
            </button>
            <button 
              onClick={() => handleQuickQuestion('Can you analyze this check image?')}
              disabled={isLoading}
            >
              ğŸ“„ Check Analysis
            </button>
            <button 
              onClick={() => handleQuickQuestion('What are investment options for beginners?')}
              disabled={isLoading}
            >
              ğŸ“ˆ Investment Advice
            </button>
          </div>
        </div>

        {/* è¾“å…¥åŒºåŸŸ */}
        <form id="chat-form" onSubmit={handleSendMessage} className="chat-input-form">
          {/* éšè—çš„æ–‡ä»¶è¾“å…¥ */}
          <input
            type="file"
            ref={fileInputRef}
            style={{ display: 'none' }}
            accept="image/*,.jpg,.jpeg,.png,.gif"
            onChange={handleImageSelect}
          />
          
          {/* æ–‡æœ¬è¾“å…¥ï¼ˆè¯­éŸ³æ¨¡å¼æ—¶æ˜¾ç¤ºå½•éŸ³æç¤ºï¼‰ */}
          {inputMode === 'voice' && isRecording ? (
            <div className="recording-indicator">
              <div className="recording-dot"></div>
              <span>Recording... Click button to stop</span>
            </div>
          ) : (
            <input
              type="text"
              className="chat-input"
              placeholder={
                inputMode === 'voice' ? 'Add optional text with your voice message...' :
                inputMode === 'image' ? 'Add description for the image...' :
                'Type your question here...'
              }
              value={inputMessage}
              onChange={(e) => setInputMessage(e.target.value)}
              disabled={isLoading || (inputMode === 'voice' && isRecording)}
            />
          )}
          
          <button 
            type="submit" 
            className="send-button"
            disabled={
              isLoading || 
              (inputMode === 'text' && !inputMessage.trim()) ||
              (inputMode === 'image' && !selectedImage)
            }
          >
            <span className="send-icon">{inputMode === 'voice' ? 'ğŸ¤' : inputMode === 'image' ? 'ğŸ“¸' : 'ğŸ“¤'}</span>
            <span className="send-text">{getSendButtonText()}</span>
          </button>
        </form>

        {/* è¯­éŸ³æ’­æ”¾æ§åˆ¶ */}
        {audioUrl && (
          <div className="audio-controls">
            <button onClick={playAudioResponse} className="play-audio-btn">
              <span>ğŸ”Š</span>
              <span>Play AI Voice Response</span>
            </button>
          </div>
        )}

        {/* åº•éƒ¨æç¤º */}
        <div className="chat-footer">
          <p>âš ï¸ Disclaimer: AI responses are for reference only. Consult bank staff for formal business.</p>
        </div>
      </div>
    </div>
  );
};

export default Chatbot;
